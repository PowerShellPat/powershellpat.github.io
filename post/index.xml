<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Patrick Contes blog</title><link>https://powershellpat.github.io/post/</link><description>Recent content in Posts on Patrick Contes blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 08 Jul 2025 22:00:32 +1000</lastBuildDate><atom:link href="https://powershellpat.github.io/post/index.xml" rel="self" type="application/rss+xml"/><item><title>Designing Egress in AWS</title><link>https://powershellpat.github.io/p/designing-egress-in-aws/</link><pubDate>Tue, 08 Jul 2025 22:00:32 +1000</pubDate><guid>https://powershellpat.github.io/p/designing-egress-in-aws/</guid><description>&lt;img src="https://powershellpat.github.io/p/designing-egress-in-aws/cover.jpeg" alt="Featured image of post Designing Egress in AWS" />&lt;h2 id="introduction">Introduction
&lt;/h2>&lt;p>AWS networking is fairly straightforward in a small setup. As a singular environment, you will generally have a single VPC that consists of:&lt;/p>
&lt;ul>
&lt;li>Subnets&lt;/li>
&lt;li>Route tables&lt;/li>
&lt;li>Network ACLs (NACLs)&lt;/li>
&lt;li>Security groups&lt;/li>
&lt;li>An Internet Gateway (IGW)&lt;/li>
&lt;li>NAT Gateway(s)&lt;/li>
&lt;/ul>
&lt;p>There are other components, and even some of the ones mentioned here may not be required. You might have a single subnet for all of your resources. Likewise, a NAT Gateway may not even be necessary (this is rare — and anyone exposing private workloads to the internet unnecessarily is not following best practice).&lt;/p>
&lt;p>But what about in more sophisticated setups, where you have multiple isolated networks in the form of several VPCs across different AWS accounts? You may need to introduce a shared services layer — an isolated VPC (or multiple, depending on your use case) that houses applications used to support your environment. Rather than duplicating these components inside each VPC, we share them (hence the name). To share these components, the VPCs need to be interconnected. AWS provides a service called Transit Gateway (TGW) to achieve exactly that, at scale.&lt;/p>
&lt;p>Building on the shared services concept, NAT Gateways provide a solution that allows private subnets to connect to the internet for outbound (egress) traffic. They are deployed into public subnets (with a default route to an IGW) so that resources can route through the NAT Gateway to access the internet. NAT Gateways aren’t strictly bound to the VPC they are deployed in — you can use them across different VPCs if you choose, by leveraging a TGW.&lt;/p>
&lt;p>With all of this context in mind, at what point does it make sense to use a NAT Gateway in each VPC (decentralised egress) versus using a TGW to route all internet traffic through a single VPC and set of NAT Gateways (centralised egress)? Which option is more cost-effective? Let’s find out.&lt;/p>
&lt;h2 id="architecture-centralised-vs-decentralised">Architecture: Centralised vs decentralised
&lt;/h2>&lt;p>Let’s begin by outlining each of the solutions and what they look like architecturally.&lt;/p>
&lt;h3 id="centralised">Centralised
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>VPC count:&lt;/strong> 4
&lt;ul>
&lt;li>&lt;strong>Workload VPCs:&lt;/strong> 3&lt;/li>
&lt;li>&lt;strong>Egress VPC:&lt;/strong> 1&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Transit Gateway count:&lt;/strong> 1
&lt;ul>
&lt;li>&lt;strong>Transit Gateway attachments:&lt;/strong> 4&lt;/li>
&lt;li>&lt;strong>Transit Gateway route tables:&lt;/strong> 1&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>NAT Gateway count:&lt;/strong> 2 (both deployed into the Egress VPC)&lt;/li>
&lt;/ul>
&lt;p>Each VPC will be associated with a single Transit Gateway (TGW) route table and propagate its routes accordingly. A default route will be configured to point to the egress VPC, enabling a centralised egress pattern.&lt;/p>
&lt;p>Each VPC will be created in a separate AWS account, except for the egress VPC, which (along with the TGW) will reside in a dedicated networking account. The TGW will be shared via AWS Resource Access Manager (RAM) to each respective AWS account, allowing TGW attachments to be created for each VPC.&lt;/p>
&lt;p>This is what the architecture looks like:
&lt;img src="https://powershellpat.github.io/p/designing-egress-in-aws/centralised.png"
width="697"
height="1125"
srcset="https://powershellpat.github.io/p/designing-egress-in-aws/centralised_hu_bace38ffe9a8c27a.png 480w, https://powershellpat.github.io/p/designing-egress-in-aws/centralised_hu_505e5e3f9f33c811.png 1024w"
loading="lazy"
alt="Centralised solution"
class="gallery-image"
data-flex-grow="61"
data-flex-basis="148px"
>&lt;/p>
&lt;h3 id="decentralised">Decentralised
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>VPC count:&lt;/strong> 3 (Workload VPCs only)&lt;/li>
&lt;li>&lt;strong>Transit Gateway count:&lt;/strong> 1
&lt;ul>
&lt;li>&lt;strong>Transit Gateway attachments:&lt;/strong> 3&lt;/li>
&lt;li>&lt;strong>Transit Gateway route tables:&lt;/strong> 1&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>NAT Gateway count:&lt;/strong> 6 (2 in each workload VPC)&lt;/li>
&lt;/ul>
&lt;p>Each VPC will be associated with a single TGW route table and will propagate its routes accordingly. This route table will &lt;strong>not&lt;/strong> contain a default route, as traffic will exit locally via each VPCs NAT Gateways before reaching the TGW.&lt;/p>
&lt;p>Each VPC will be created in separate AWS accounts. The TGW will again be created in the networking account and RAM shared to each AWS account to allow for TGW attachments per VPC.&lt;/p>
&lt;p>This is what the architecture looks like:
&lt;img src="https://powershellpat.github.io/p/designing-egress-in-aws/decentralised.png"
width="701"
height="1035"
srcset="https://powershellpat.github.io/p/designing-egress-in-aws/decentralised_hu_d0d8ba7e79e8c972.png 480w, https://powershellpat.github.io/p/designing-egress-in-aws/decentralised_hu_8cfe4ff35c53ecea.png 1024w"
loading="lazy"
alt="Decentralised solution"
class="gallery-image"
data-flex-grow="67"
data-flex-basis="162px"
>&lt;/p>
&lt;p>Now that the architectures are defined, let’s dig deeper into the pricing of each component.&lt;/p>
&lt;h2 id="pricing-models">Pricing models
&lt;/h2>&lt;h3 id="nat-gateways">NAT Gateways
&lt;/h3>&lt;p>NAT Gateways have a simple pricing model. You pay for two main things:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Hourly cost per NAT Gateway&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Data processed (in GB) by the NAT Gateway&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>The source or destination of the traffic is irrelevant — if the data passes through the NAT Gateway, you&amp;rsquo;re paying for it.&lt;/p>
&lt;p>In addition to NAT Gateway costs, there are data transfer fees for services like EC2. This includes:&lt;/p>
&lt;ul>
&lt;li>Traffic going out to the internet&lt;/li>
&lt;li>Traffic sent to other AWS regions&lt;/li>
&lt;li>Traffic sent between Availability Zones (AZs) within the same region&lt;/li>
&lt;/ul>
&lt;p>It’s also worth mentioning that &lt;strong>VPCs themselves are free&lt;/strong>. While components inside a VPC (like NAT Gateways) may incur costs, the VPC construct has no cost on its own. So for this comparison, we’ll only factor in the pricing for NAT Gateways.&lt;/p>
&lt;h3 id="transit-gateways">Transit Gateways
&lt;/h3>&lt;p>Transit Gateways follow a similar pricing model to NAT Gateways. You pay for:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Hourly cost per Transit Gateway attachment&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Data processed (in GB) by the Transit Gateway&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>As with NAT Gateways, data transfer fees for services like EC2 still apply and should be considered — especially for inter-AZ or inter-region traffic.&lt;/p>
&lt;h2 id="cost-breakdown">Cost breakdown
&lt;/h2>&lt;p>To calculate actual costs, we need to use the pricing from an AWS region. For this exercise, we’ll use the &lt;strong>AWS Sydney region&lt;/strong> (&lt;code>ap-southeast-2&lt;/code>). Based on this region, the pricing is as follows:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>NAT Gateway&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>Hourly fee:&lt;/strong> $0.059&lt;/li>
&lt;li>&lt;strong>Per GB of data processed:&lt;/strong> $0.059&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Transit Gateway:&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>Hourly fee (per attachment):&lt;/strong> $0.07&lt;/li>
&lt;li>&lt;strong>Per GB of data processed:&lt;/strong> $0.02&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>For both the centralised and decentralised solutions already outlined, we’ll assume &lt;strong>100 GB of data processed&lt;/strong> in total. We’ll also assume a billing duration of &lt;strong>30 days (720 hours)&lt;/strong> for the hourly costs.&lt;/p>
&lt;p>Although both solutions will incur data transfer fees (e.g. to the internet, to other AWS regions, or between AZs within a region), these are identical in both cases. As such, we’ve &lt;strong>excluded&lt;/strong> them from this comparison to focus only on the NAT and Transit Gateway pricing.&lt;/p>
&lt;h3 id="centralised-cost-breakdown">Centralised cost breakdown
&lt;/h3>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Component&lt;/th>
&lt;th>Cost&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>NAT Gateway 1 (hourly fee)&lt;/td>
&lt;td>$42.48&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NAT Gateway 2 (hourly fee)&lt;/td>
&lt;td>$42.48&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NAT Gateway (data processing)&lt;/td>
&lt;td>$5.90&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Transit Gateway (Egress VPC attachment)&lt;/td>
&lt;td>$50.40&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Transit Gateway (Workload A VPC attachment)&lt;/td>
&lt;td>$50.40&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Transit Gateway (Workload B VPC attachment)&lt;/td>
&lt;td>$50.40&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Transit Gateway (Workload C VPC attachment)&lt;/td>
&lt;td>$50.40&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Transit Gateway (data processing)&lt;/td>
&lt;td>$2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Total&lt;/strong>&lt;/td>
&lt;td>&lt;strong>$294.46&lt;/strong>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="decentralised-cost-breakdown">Decentralised cost breakdown
&lt;/h3>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Component&lt;/th>
&lt;th>Cost&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>NAT Gateway 1 (hourly fee)&lt;/td>
&lt;td>$42.48&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NAT Gateway 2 (hourly fee)&lt;/td>
&lt;td>$42.48&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NAT Gateway 3 (hourly fee)&lt;/td>
&lt;td>$42.48&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NAT Gateway 4 (hourly fee)&lt;/td>
&lt;td>$42.48&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NAT Gateway 5 (hourly fee)&lt;/td>
&lt;td>$42.48&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NAT Gateway 6 (hourly fee)&lt;/td>
&lt;td>$42.48&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NAT Gateway (data processing)&lt;/td>
&lt;td>$5.90&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Transit Gateway (Workload A VPC attachment)&lt;/td>
&lt;td>$50.40&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Transit Gateway (Workload B VPC attachment)&lt;/td>
&lt;td>$50.40&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Transit Gateway (Workload C VPC attachment)&lt;/td>
&lt;td>$50.40&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Transit Gateway (data processing)&lt;/td>
&lt;td>$2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Total&lt;/strong>&lt;/td>
&lt;td>&lt;strong>$413.98&lt;/strong>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="findings">Findings
&lt;/h2>&lt;p>With the findings in tow, it&amp;rsquo;s clear which solution is more cost-effective based on the defined setup. The &lt;strong>centralised egress solution&lt;/strong> comes out ahead in terms of cost when compared to the decentralised one — &lt;strong>as long as the assumptions hold.&lt;/strong>&lt;/p>
&lt;p>However, there are edge cases worth exploring. Also, note that we used a &amp;ldquo;magic number&amp;rdquo; of &lt;strong>6 NAT Gateways&lt;/strong> in the decentralised setup — something we’ll expand on shortly.&lt;/p>
&lt;h3 id="what-if-fewer-vpcs-needed-egress">What if fewer VPCs needed egress?
&lt;/h3>&lt;p>Suppose only &lt;strong>one of the three workload VPCs&lt;/strong> in the decentralised solution actually required egress access (and therefore NAT Gateways). If you removed &lt;strong>4 of the 6&lt;/strong> NAT Gateways, your total would drop to &lt;strong>$244.06 — cheaper than the centralised solution.&lt;/strong>&lt;/p>
&lt;h3 id="what-if-you-removed-the-transit-gateway">What If You Removed the Transit Gateway?
&lt;/h3>&lt;p>Now imagine removing the Transit Gateway from the decentralised solution entirely, and each of the &lt;strong>three VPCs&lt;/strong> had their own &lt;strong>local NAT Gateways&lt;/strong>, but no interconnection. In that case, the total cost would come to &lt;strong>$260.78&lt;/strong> — not as low as the previous example, but &lt;strong>still cheaper than the centralised solution&lt;/strong> (at $294.46).&lt;/p>
&lt;h3 id="why-we-used-3-vpcs-as-a-baseline">Why We Used 3 VPCs as a Baseline
&lt;/h3>&lt;p>The reason we compared &lt;strong>three workload VPCs&lt;/strong> and &lt;strong>6 NAT Gateways&lt;/strong> is that this configuration represents a cost-efficiency threshold. Beyond this point, the &lt;strong>decentralised approach starts to suffer from diminishing returns.&lt;/strong>&lt;/p>
&lt;p>While it may seem obvious to adopt a centralised solution, there&amp;rsquo;s a case to be made for starting with decentralised egress — especially in &lt;strong>early-stage AWS environments&lt;/strong> that aren’t yet interconnected. If the VPCs remain isolated, decentralised egress might be more cost-effective. But &lt;strong>as soon as inter-VPC connectivity is required&lt;/strong>, the decentralised model becomes significantly less economical.&lt;/p>
&lt;h3 id="additional-cost-scenarios">Additional cost scenarios
&lt;/h3>&lt;p>Here are some expanded scenarios to help illustrate the cost impact at scale:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Scenario&lt;/th>
&lt;th>Total Cost&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Decentralised: 4 VPCs, 8 NAT Gateways, 0 TGW&lt;/td>
&lt;td>$345.74&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Centralised: 4 VPCs + 1 egress VPC, 2 NAT Gateways, 5 TGW attachments&lt;/td>
&lt;td>$344.86&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Decentralised: 5 VPCs, 10 NAT Gateways, 0 TGW&lt;/td>
&lt;td>$430.70&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Centralised: 5 VPCs + 1 egress VPC, 2 NAT Gateways, 6 TGW attachments&lt;/td>
&lt;td>$395.26&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>As shown above, once you pass three VPCs, the centralised model quickly becomes more attractive from a cost perspective.&lt;/p>
&lt;h2 id="centralised-solution-benefits">Centralised solution benefits
&lt;/h2>&lt;p>While the primary focus of this blog is cost, not everything comes down to price. Ultimately, the real question is: &lt;strong>what are you willing to pay for best practice and a secure, scalable setup?&lt;/strong>&lt;/p>
&lt;p>AWS provides several services that enhance security at the networking layer. Two key examples include:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>AWS Network Firewall&lt;/strong> – a fully managed stateful firewall service&lt;/li>
&lt;li>&lt;strong>Gateway Load Balancer (GWLB)&lt;/strong> – supports third-party firewalls in a “bump-in-the-wire” architecture&lt;/li>
&lt;/ul>
&lt;p>Both of these services are designed to operate in a centralised model, enabling consistent inspection of traffic — whether it&amp;rsquo;s north/south (in and out of the AWS network) or east/west (between VPCs/subnets). Any traffic that bypasses these centralised inspection points risks being unauthorised or even malicious. Without a centralised architecture, enforcing an inspection solution across multiple VPCs becomes near impossible.&lt;/p>
&lt;p>If you needed any more reasons to lean toward a centralised model — regardless of cost — the ability to integrate services like AWS Network Firewall and Gateway Load Balancer should be near the top of the list.&lt;/p>
&lt;h2 id="conclusion">Conclusion
&lt;/h2>&lt;p>Egress traffic in AWS must traverse some kind of gateway to reach the internet. For private subnets, this means using a &lt;strong>NAT Gateway&lt;/strong>. As we’ve explored, NAT Gateways can either be &lt;strong>local to each VPC&lt;/strong> or located in a &lt;strong>centralised egress VPC&lt;/strong>, connected via a &lt;strong>Transit Gateway.&lt;/strong>&lt;/p>
&lt;p>Centralised solutions work best at scale and offer stronger alignment with AWS’s security services. Decentralised solutions, on the other hand, are often more suitable for &lt;strong>smaller environments&lt;/strong> — either early in their cloud journey or intentionally minimal in scope.&lt;/p>
&lt;p>The next time you&amp;rsquo;re designing how traffic should leave your AWS environment, consider the &lt;strong>long-term direction, cost implications, security posture&lt;/strong>, and — most importantly — &lt;strong>what the environment needs to function effectively.&lt;/strong>&lt;/p>
&lt;p>Cover image generated by &lt;a class="link" href="https://deepai.org/" target="_blank" rel="noopener"
>DeepAI&lt;/a>&lt;/p></description></item><item><title>Perfect vs Practical: How to know when an IT Solution is ready</title><link>https://powershellpat.github.io/p/perfect-vs-practical-how-to-know-when-an-it-solution-is-ready/</link><pubDate>Thu, 12 Jun 2025 22:20:32 +1000</pubDate><guid>https://powershellpat.github.io/p/perfect-vs-practical-how-to-know-when-an-it-solution-is-ready/</guid><description>&lt;img src="https://images.unsplash.com/photo-1624961151169-b3df5c0f06ab?q=80&amp;w=882&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.1.0&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" alt="Featured image of post Perfect vs Practical: How to know when an IT Solution is ready" />&lt;h2 id="introduction">Introduction
&lt;/h2>&lt;p>Designing IT solutions is a challenging task. Not only do you need to take several factors into consideration, but you also need to understand the lifecycle of what you’re designing. Questions will inevitably pop into your head, like:&lt;/p>
&lt;ul>
&lt;li>How long does this solution need to last?&lt;/li>
&lt;li>Is it going to be perpetual?&lt;/li>
&lt;li>How do we handle high availability and disaster recovery?&lt;/li>
&lt;li>When will I know it&amp;rsquo;s complete?&lt;/li>
&lt;/ul>
&lt;p>That last point—&lt;em>when will I know it&amp;rsquo;s complete?&lt;/em>—can be ambiguous. Does it mean the solution is fully fleshed out and working at the desired end state? Or does it mean it&amp;rsquo;s ready once a Minimum Viable Product (MVP) has been constructed?&lt;/p>
&lt;p>If the solution is too simple, it may lack features or fail to scale. But if it’s too complex—over-engineered—it might introduce unexpected bugs and hurt not just our credibility, but also the brand we represent, especially in a corporate context. And beyond the bugs, what about the cost of building that solution? Our time? Money? Resources? All potentially wasted on something that doesn’t deliver a meaningful return on investment.&lt;/p>
&lt;p>It’s a conundrum, no doubt. But there are frameworks and considerations that help you draw the line and confidently mark a solution as done based on criteria.&lt;/p>
&lt;h2 id="understanding-a-solution">Understanding a solution
&lt;/h2>&lt;p>One of the first fundamental skills that you need to understand as a Consultant or anyone in a role that involves designing or architecting solutions—is the ability to understand the &lt;strong>what&lt;/strong> and the &lt;strong>why&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>What&lt;/strong> are we doing?&lt;/li>
&lt;li>&lt;strong>What&lt;/strong> are we building?&lt;/li>
&lt;li>&lt;strong>What&lt;/strong> is it?&lt;/li>
&lt;li>&lt;strong>What&lt;/strong> will it be?&lt;/li>
&lt;/ul>
&lt;p>Once we understand that &lt;strong>what&lt;/strong>, we move on to the &lt;strong>why&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Why&lt;/strong> are we doing this?&lt;/li>
&lt;li>&lt;strong>Why&lt;/strong> are we building this?&lt;/li>
&lt;li>&lt;strong>Why&lt;/strong> do we need to include x, y and z?&lt;/li>
&lt;li>&lt;strong>Why&lt;/strong> is this or that a good idea?&lt;/li>
&lt;/ul>
&lt;p>All of those &lt;em>what&lt;/em> and &lt;em>why&lt;/em> questions can be summarised in a single word: requirements. Requirements are the driving force behind the rationale. They help shape what the solution will look like and give context to the decisions made along the way. They set the direction—establishing goals, coordinating efforts across teams, and managing expectations for stakeholders. From a commercial perspective, requirements are assessed and translated into elements such as &lt;strong>definition of done&lt;/strong> and/or &lt;strong>acceptance criteria&lt;/strong>. These elements are then used in commercial agreements like a &lt;strong>Statement of Work (SoW)&lt;/strong> to provide clear and concise deliverables for all parties involved.&lt;/p>
&lt;p>When we understand the requirements of what we’re setting out to do, we have structure. That structure becomes the foundation for a plan—where ideas take shape and strategy begins to form. As you become more proficient in your craft—whether it’s software, infrastructure, or something else—you’ll begin to recognise patterns. You’ll recall what worked well and what didn’t in previous experiences. Armed with that insight, you’ll feel more confident when similar situations arise, and better equipped to act early—before issues have a chance to fester.&lt;/p>
&lt;h2 id="the-definition-of-complete">The definition of complete
&lt;/h2>&lt;p>Now comes the tricky part of this process: &lt;em>What defines a solution as complete?&lt;/em>&lt;/p>
&lt;ul>
&lt;li>Is it something that we can measure?&lt;/li>
&lt;li>Does it relate to its run cost?&lt;/li>
&lt;li>Can it handle the load we need it to?&lt;/li>
&lt;li>Will it accumulate technical debt?&lt;/li>
&lt;/ul>
&lt;p>We do have frameworks and tools to help answer these questions. In the previous section on understanding a solution, we mentioned the &lt;strong>definition of done&lt;/strong> and &lt;strong>acceptance criteria&lt;/strong>. Depending on how mature the environment and organisation are, these could be loosely defined or meticulously detailed. By using these elements, we can clearly describe what a “complete” solution looks like—aligned with what we’re trying to achieve &lt;strong>now&lt;/strong>.&lt;/p>
&lt;p>Even though we use the term “complete”, it doesn’t always mean the end state. More often, it marks a meaningful checkpoint. The future state will continue to evolve—just as the broader IT landscape constantly shifts.&lt;/p>
&lt;p>A definition of done may reflect a &lt;strong>simple&lt;/strong>, even traditional, solution. Solutions don’t need to be extravagant if they fulfill the basic requirements. There’s nothing wrong with doing things the old-fashioned way. Take mainframes, for example. You might think of them as legacy tech from the 1960s—but would it surprise you to know that many major corporations across sectors like finance, government, and healthcare still rely on mainframes today to process transactions? Mainframes continue to hold relevance because of their unique capabilities and the critical roles they play in these industries. Could they be replaced by modern stacks like serverless architectures? Probably. Is it a simple task? Absolutely not.&lt;/p>
&lt;p>The mainframe example highlights two key principles:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>If it isn’t broken, don’t fix it&lt;/strong> — or in other words, if it works, don’t change it.&lt;/li>
&lt;li>&lt;strong>Old technology doesn’t automatically mean obsolete&lt;/strong> — in fact, as older generations retire, we might even see a kind of renaissance for legacy technologies like mainframes.&lt;/li>
&lt;/ol>
&lt;p>At one point in history, mainframes were considered the north star of computing. Fast forward to today, and our modern-day north stars might be serverless platforms that run only your code—or perhaps AI-powered observability systems that proactively detect anomalies.&lt;/p>
&lt;p>Technology doesn’t stand still. It evolves rapidly. Today, we’re seeing explosive growth in AI, particularly with agentic models that leverage Model Context Protocol (MCP) servers.&lt;/p>
&lt;p>So when it comes to defining what makes a solution &amp;ldquo;complete,&amp;rdquo; remember these quick tidbits:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>It’s fit for purpose.&lt;/strong> It doesn’t need to last forever—just for today, tomorrow, and the near future. Solutions will always evolve.&lt;/li>
&lt;li>&lt;strong>It will scale within reason.&lt;/strong> If you’re expecting millions of requests per second, architect accordingly. But if you&amp;rsquo;re only handling a few per second, you don’t need a massive data platform with all the bells and whistles that might cost thousands per month to run.&lt;/li>
&lt;li>&lt;strong>It will work.&lt;/strong> This is the core of it all. “Working” might mean different things to different people, but ultimately, the solution behaves as intended and delivers on its purpose.&lt;/li>
&lt;/ul>
&lt;h2 id="over-engineering-and-its-ramifications">Over-engineering and its ramifications
&lt;/h2>&lt;p>So what happens when we go to the other extreme? Rather than stopping at our definition of done, we push way past it and engineer the hell out of a solution. It’s amazing! It’s something to behold!&lt;/p>
&lt;p>…Or is it?&lt;/p>
&lt;p>How far down the rabbit hole did you have to go to get there?
And ultimately—what was the cost?&lt;/p>
&lt;p>Over-engineering is contextual. When it does happen, it can manifest in different forms depending on the solution. One of the worst forms is trying to account for every possible future use case—a “just in case” mindset. Building a solution to handle everything that &lt;em>might&lt;/em> happen in the future can stifle progress. It can halt or delay the project until there is mutual resolution amongst stakeholders, all while delaying progress to the end goal. In situations like this, I often use the saying: &lt;strong>“the juice isn’t worth the squeeze.”&lt;/strong> In other words, to achieve &lt;em>X&lt;/em>, we need to do &lt;em>Y&lt;/em>—and &lt;em>Y&lt;/em> just isn’t worth the investment of our time, resources, or mental energy.&lt;/p>
&lt;p>Another form of over-engineering is adding unnecessary complexity. The &lt;strong>maturity&lt;/strong> of a solution must be factored in when architecting. Introducing advanced complexity to a system that’s not ready for it can be wasteful, or even damaging. Take a startup, for example. Let’s say their core revenue-driving product is a piece of software. Right now, that software runs on a single PC under someone’s desk. Is it elegant? No. Does it work for &lt;em>now&lt;/em>? Actually, yes—in a very non-ideal way.&lt;/p>
&lt;p>If that same startup tries to launch into a cutting-edge, serverless cloud architecture with auto-scaling, CI/CD pipelines, and bleeding-edge automation—&lt;strong>but has no current need for it&lt;/strong>—that effort would be a catastrophe. The resources required to build and support such a setup would likely never see a return, especially if the startup is still finding product-market fit or struggling with cash flow. In fact, they might run out of steam entirely and fold before realising their goals.&lt;/p>
&lt;p>A solution shouldn’t be &lt;strong>too top-heavy&lt;/strong> at the start. By that, I mean: don’t add features or components that don’t bring actual value in the near term. Later—once things stabilize and there’s a clear path forward—it might make sense to revisit and layer in those “nice to have” features. But early on, they often just weigh you down.&lt;/p>
&lt;h2 id="return-on-investment-roi-and-building-momentum">Return on Investment (ROI) and building momentum
&lt;/h2>&lt;p>After we get through the rigorous process of vetting the solution using the mechanisms already mentioned, we need to shift into a mindset that focuses on &lt;strong>vision&lt;/strong>—the long-term outlook for the solution. As part of this vision, we must consider how we extract value over time and achieve a solid return on investment (ROI). But ROI isn’t always about money. There are other forms of currency we “spend” to make a solution functional and successful. These include:&lt;/p>
&lt;ul>
&lt;li>Time&lt;/li>
&lt;li>Effort&lt;/li>
&lt;li>On-going support&lt;/li>
&lt;li>Business integration&lt;/li>
&lt;/ul>
&lt;p>Let’s start with &lt;strong>time&lt;/strong>. It’s one of our most precious resources—yet most of us (myself included) never seem to have enough of it. In the digital age, it’s easy to jump from watching Judge Judy on YouTube to checking sports results, reading the latest tariff news, playing a video game, or falling into a social media rabbit hole. There’s always something waiting to eat into our time.&lt;/p>
&lt;p>So, when we invest time into a solution, it should give us time back. The return should come in the form of &lt;strong>efficiency&lt;/strong> or &lt;strong>automation&lt;/strong>. This is especially true when adopting DevOps methodologies, where the whole premise is to automate as much of your role as possible—freeing you up for higher-value tasks.&lt;/p>
&lt;p>Another often-overlooked factor is the &lt;strong>longevity of the solution&lt;/strong> and what ongoing support and maintenance will look like. Simple systems might be seen as ancient by today’s standards—but they can also be the easiest to maintain, debug, and enhance. A “good enough” solution &lt;em>today&lt;/em> often beats a “perfect” one six months from now.&lt;/p>
&lt;p>A solution that is well-vetted, tested, iterated upon, intuitive, and clearly defined delivers strong ROI—not just for development teams, but also for project managers, business stakeholders, and end users. When more people begin interacting with the solution, momentum builds. Feedback loops form, giving valuable insight into what to improve or prioritise next.&lt;/p>
&lt;p>This is how momentum turns into progress.
This is how “good enough” evolves into &lt;strong>great&lt;/strong>.&lt;/p>
&lt;h2 id="conclusion">Conclusion
&lt;/h2>&lt;p>The next time you&amp;rsquo;re designing a solution—or playing a role in shaping one—consider what’s &lt;strong>practical&lt;/strong> to get it working now, versus what’s &lt;strong>“perfect”&lt;/strong> but loaded with nice-to-have features that may not add much value.&lt;/p>
&lt;p>Don’t get stuck in the weeds and chase those rabbits too deep into those holes! While it can be fun to experiment and theory-craft, a good engineer or architect knows when they&amp;rsquo;ve gone deep enough to achieve a solid result for a reasonable amount of effort.
In the end, completing a solution up until a point isn’t settling. It&amp;rsquo;s being strategic.&lt;/p>
&lt;p>&lt;em>Cover image by &lt;a class="link" href="https://unsplash.com/@lucasdixsept" target="_blank" rel="noopener"
>dix sept&lt;/a> on Unsplash&lt;/em>&lt;/p></description></item></channel></rss>